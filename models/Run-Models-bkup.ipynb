{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Models (includes RandomForest and XGBoost)\n",
        "\n",
        "Documentation\n",
        "https://model.earth/RealityStream  \n",
        "https://model.earth/RealityStream/input/industries backed-up to Run-Models-bkup.ipynb\n",
        "\n",
        "Haohao: Loading parameters.yaml file and saving as custom configs on colab user's Google Drive    \n",
        "https://raw.githubusercontent.com/ModelEarth/RealityStream/main/parameters.yaml\n",
        "\n",
        "DONE Aashish: Used Pandas for integrated_df (became df) to avoid loading saved .csv files when in Colab at Google.com.  \n",
        "DONE Loren: Load parameters.yaml and save locally for customization.  \n",
        "https://chatgpt.com/share/e4a2ee73-ab74-4551-9868-37b9b5b6b359  \n",
        "\n",
        "TO DO: In the same panel as each accuracy report, call a new function called displayModelHeader to display the model name (as a bold header) and the file paths for features and targets above the report.\n",
        "\n",
        "TO DO: Add a path parameter that pulls from [all-years](https://colab.research.google.com/drive/1zu0WcCiIJ5X3iN1Hd1KSW4dGn0JuodB8#scrollTo=jxZiI7xcrT4B) generated by our [Industry Features CoLab](https://colab.research.google.com/drive/1HJnuilyEFjBpZLrgxDa4S0diekwMeqnh?usp=sharing)\n",
        "\n",
        "TO DO: Load 1 of these 4 bee targets using parameters.yaml setting, remove bees hardcoding from colab\n",
        "https://github.com/ModelEarth/RealityStream/tree/main/input/bees/targets  \n",
        "\n",
        "TO DO: Load targets from Google Data Commons by calling a separate python file.  \n",
        "https://reality.streamlit.app/?parameters=https://raw.githubusercontent.com/ModelEarth/RealityStream/main/parameters.yaml"
      ],
      "metadata": {
        "id": "jxZiI7xcrT4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtFKCS4LkOzN"
      },
      "outputs": [],
      "source": [
        "save_training = True  # When False, Pandas is used.\n",
        "\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import yaml\n",
        "import requests\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n7VobtSxaEhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default parameters file and local path to save at.\n",
        "# After running you can edit parameters that appear to the right.\n",
        "# Coming soon:\n",
        "# You can change the bees year in the targets.path to: 2007, 2012, 1017, 2022\n",
        "# TO DO: Changing the year in the bees target does not work yet. Make updates to other panels.\n",
        "parametersSource = \"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/parameters.yaml\"\n",
        "importNewParameters = True\n",
        "overwriteExistingParameter = False\n",
        "localParametersPath = '/content/parametersLocal.yaml'\n",
        "\n",
        "# Fetch the parameters from the source URL\n",
        "response = requests.get(parametersSource)\n",
        "parametersSourceData = yaml.safe_load(response.content)\n",
        "\n",
        "# Function to merge dictionaries\n",
        "def merge_dicts(source, local, import_new, overwrite_existing):\n",
        "    for key, value in source.items():\n",
        "        if key in local:\n",
        "            if isinstance(value, dict) and isinstance(local[key], dict):\n",
        "                merge_dicts(value, local[key], import_new, overwrite_existing)\n",
        "            elif overwrite_existing:\n",
        "                local[key] = value\n",
        "        else:\n",
        "            if import_new:\n",
        "                local[key] = value\n",
        "\n",
        "class DictToObject:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            if isinstance(value, dict):\n",
        "                value = DictToObject(value)\n",
        "            self.__dict__[key] = value\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.__dict__[key]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        self.__dict__[key] = value\n",
        "\n",
        "# Load local parameters if they exist\n",
        "if os.path.exists(localParametersPath):\n",
        "    with open(localParametersPath, 'r') as file:\n",
        "        parametersLocalData = yaml.safe_load(file)\n",
        "else:\n",
        "    parametersLocalData = {}\n",
        "\n",
        "# Merge parameters according to specified rules\n",
        "merge_dicts(parametersSourceData, parametersLocalData, importNewParameters, overwriteExistingParameter)\n",
        "\n",
        "# Save the merged parameters locally\n",
        "with open(localParametersPath, 'w') as file:\n",
        "    yaml.dump(parametersLocalData, file)\n",
        "\n",
        "# Display local parameters file in the left side of Colab\n",
        "from google.colab import files\n",
        "files.view(localParametersPath)"
      ],
      "metadata": {
        "id": "LRqQNpac3jeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "68c8e012-c94f-4de5-9f91-84630e9ec5d6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/parametersLocal.yaml\")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Parameters\n",
        "# Load local parameters and print below.\n",
        "\n",
        "import yaml\n",
        "\n",
        "localParametersPath = '/content/parametersLocal.yaml'\n",
        "\n",
        "# Load parameters from the local file\n",
        "with open(localParametersPath, 'r') as file:\n",
        "    param_dict = yaml.safe_load(file)\n",
        "\n",
        "# Convert dictionary to an object with dot notation access\n",
        "param = DictToObject(param_dict)\n",
        "\n",
        "# Print the parameters\n",
        "def print_param(obj, indent=0):\n",
        "    for key in obj.__dict__.keys():\n",
        "        value = getattr(obj, key)\n",
        "        if isinstance(value, DictToObject):\n",
        "            print(' ' * indent + f\"{key}:\")\n",
        "            print_param(value, indent + 2)\n",
        "        else:\n",
        "            print(' ' * indent + f\"{key}: {value}\")\n",
        "\n",
        "# Also not in use yet, these will only be used if parametersLocal.yaml omits.\n",
        "features_data = param['features']['data'] # \"industries\"\n",
        "features_path = param['features']['path'] # \"https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\"\n",
        "targets_data  = param['targets']['data'] # \"bees\"\n",
        "targets_path  = param['targets']['path'] # \"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\"\n",
        "\n",
        "print_param(param)\n",
        "print(\"\\nparam.targets.data:\", param.targets.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alauCxr5yHF7",
        "outputId": "d9561fca-8883-4fda-e3da-1f7063b59849"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features:\n",
            "  data: industries\n",
            "  endyear: 2021\n",
            "  naics: [2, 4, 6]\n",
            "  path: https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\n",
            "  startyear: 2017\n",
            "  state: ME\n",
            "models: rbf\n",
            "targets:\n",
            "  data: bees\n",
            "  path: https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2017.csv\n",
            "\n",
            "param.targets.data: bees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: Setting model_name = \"XGBoost\" resulted in the error:\n",
        "# ValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Population-2018: object, Population-2019: object, Population-2020: object\n",
        "\n",
        "# TO DO: These are in use, replace with parameters\n",
        "\n",
        "dataset_name = \"bees\"  # TO DO: eliminate since features and targets will differ.\n",
        "model_name = \"RandomForest\"  # Specify the model to be trained\n",
        "all_model_list = [\"LogisticRegression\", \"SVM\", \"MLP\", \"RandomForest\", \"XGBoost\"]  # All usable models\n",
        "assert model_name in all_model_list\n",
        "valid_report_list = [\"RandomForest\", \"XGBoost\"]  # All valid models to generate feature-importance report\n",
        "\n",
        "random_state = 42  # Specify random state\n",
        "\n",
        "# Feature related information:\n",
        "country = \"US\"\n",
        "years = range(2017, 2022)\n",
        "naics_level = 2\n",
        "naics_list = [2, 4, 6]\n",
        "assert naics_level in naics_list\n",
        "\n",
        "# Target related information:\n",
        "target_url = f\"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/{dataset_name}/targets/{dataset_name}-targets.csv\"\n",
        "target_df = pd.read_csv(target_url)  # Get the target csv\n",
        "\n",
        "if dataset_name == \"bees\":  # Eliminate these lines after switching to parameters.yaml settings\n",
        "    target_column = '2022_increase'  # Specify the target column\n",
        "    target_list = ['2007_increase', '2012_increase', '2017_increase', '2022_increase']  # Specify all usable target columns\n",
        "    target_list.remove(target_column)  # Drop the one we are interested in\n",
        "\n",
        "year_list = [\"2002\", \"2007\", \"2012\", \"2017\", \"2022\"]\n",
        "drop_list = ['Unnamed: 0', 'Name', 'State', 'State ANSI', 'County ANSI', \"Ag District\", \"Ag District Code\"]\n",
        "all_drop_list = drop_list + target_list + year_list  # Drop all columns that can affect the training procedure or are not related\n",
        "\n",
        "feature_start_idx = 3  # Specify the starting column index in dataset csv for features, where first few columns are for target and id related stuff\n",
        "target_idx = 0  # Specify the column index for target\n",
        "\n",
        "# Directory Information:\n",
        "merged_save_dir = f\"../process/{dataset_name}/states-{target_column}-{dataset_name}\"  # Specify the saving dir for state-separate dataset\n",
        "full_save_dir = f\"../output/{dataset_name}/training\"  # Specify the saving dir for the integrated dataset\n"
      ],
      "metadata": {
        "id": "Z12cWU4y09on"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IdUt24w63WDa"
      },
      "outputs": [],
      "source": [
        "# STEP: Get Dictionaries for states and industries\n",
        "STATE_DICT = {\n",
        "    \"AL\": \"ALABAMA\",\"AK\": \"ALASKA\",\"AZ\": \"ARIZONA\",\"AR\": \"ARKANSAS\",\"CA\": \"CALIFORNIA\",\"CO\": \"COLORADO\",\"CT\": \"CONNECTICUT\",\"DE\": \"DELAWARE\",\"FL\": \"FLORIDA\",\"GA\": \"GEORGIA\",\"HI\": \"HAWAII\",\"ID\": \"IDAHO\",\"IL\": \"ILLINOIS\",\"IN\": \"INDIANA\",\"IA\": \"IOWA\",\"KS\": \"KANSAS\",\"KY\": \"KENTUCKY\",\"LA\": \"LOUISIANA\",\"ME\": \"MAINE\",\"MD\": \"MARYLAND\",\"MA\": \"MASSACHUSETTS\",\"MI\": \"MICHIGAN\",\"MN\": \"MINNESOTA\",\"MS\": \"MISSISSIPPI\",\"MO\": \"MISSOURI\",\"MT\": \"MONTANA\",\"NE\": \"NEBRASKA\",\"NV\": \"NEVADA\",\"NH\": \"NEW HAMPSHIRE\",\"NJ\": \"NEW JERSEY\",\"NM\": \"NEW MEXICO\",\"NY\": \"NEW YORK\",\"NC\": \"NORTH CAROLINA\",\"ND\": \"NORTH DAKOTA\",\"OH\": \"OHIO\",\"OK\": \"OKLAHOMA\",\"OR\": \"OREGON\",\"PA\": \"PENNSYLVANIA\",\"RI\": \"RHODE ISLAND\",\"SC\": \"SOUTH CAROLINA\",\"SD\": \"SOUTH DAKOTA\",\"TN\": \"TENNESSEE\",\"TX\": \"TEXAS\",\"UT\": \"UTAH\",\"VT\": \"VERMONT\",\"VA\": \"VIRGINIA\",\"WA\": \"WASHINGTON\",\"WV\": \"WEST VIRGINIA\",\"WI\": \"WISCONSIN\",\"WY\": \"WYOMING\"\n",
        "}\n",
        "try:\n",
        "    industries_df = pd.read_csv(f\"https://raw.githubusercontent.com/ModelEarth/community-data/master/{country.lower()}/id_lists/naics{naics_level}.csv\",header=None)\n",
        "    INDUSTRIES_DICT = industries_df.set_index(0).to_dict()[1]\n",
        "except:\n",
        "    INDUSTRIES_DICT = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jv_AUQwjnrkN"
      },
      "outputs": [],
      "source": [
        "# STEP: Create Functions\n",
        "def rename_columns(df, year):\n",
        "    rename_mapping = {}\n",
        "    for column in df.columns:\n",
        "      if column not in df.columns[:2]:\n",
        "          new_column_name = column + f'-{year}'\n",
        "          rename_mapping[column] = new_column_name\n",
        "\n",
        "    df.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "def check_directory(directory_path): # Check whether the given directory exists, if not, then create it\n",
        "    if not os.path.exists(directory_path):\n",
        "        try:\n",
        "            os.makedirs(directory_path)\n",
        "            print(f\"Directory '{directory_path}' created successfully.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error creating directory '{directory_path}': {e}\")\n",
        "    else:\n",
        "        print(f\"Directory '{directory_path}' already exists.\")\n",
        "    return directory_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP: Merge feature and target data\n",
        "# If save_training=True, your files will reside in the \"process\" folder to the left.\n",
        "# Hit the refresh icon above your folder list to the left.\n",
        "if save_training:\n",
        "    save_dir = merged_save_dir  # Save in the local directory if save_training is True\n",
        "\n",
        "check_directory(save_dir)\n",
        "\n",
        "# State-separately, for each state, merging industry features and target on Fips value and County Name, return the merged csv\n",
        "\n",
        "for state in STATE_DICT:\n",
        "    data = {}\n",
        "    for year in years:\n",
        "        url = f\"https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics_level}/{country}/counties/{year}/{country}-{state}-training-naics{naics_level}-counties-{year}.csv\"\n",
        "        data[year] = pd.read_csv(url)\n",
        "        rename_columns(data[year], year)\n",
        "\n",
        "    merged_df_feature = pd.merge(data[2017], data[2018], on=['Fips', 'Name'], how='inner')\n",
        "    for year in range(2019, 2022):\n",
        "        merged_df_feature = pd.merge(merged_df_feature, data[year], on=['Fips', 'Name'], how='inner')\n",
        "\n",
        "    cols = merged_df_feature.columns.tolist()\n",
        "    cols = cols[:2] + sorted(cols[2:])\n",
        "    merged_df_feature = merged_df_feature[cols].rename(columns={\"Name\": \"County\"})\n",
        "\n",
        "    merged_df = pd.merge(merged_df_feature, target_df[target_df[\"State\"] == STATE_DICT[state]], on=[\"Fips\", \"County\"], how=\"inner\")\n",
        "    merged_df.drop(columns=all_drop_list, axis=1, inplace=True)\n",
        "\n",
        "    target = merged_df.iloc[:, -1]\n",
        "    merged_df.drop(columns=[target_column], axis=1, inplace=True)\n",
        "    merged_df.insert(0, 'target', target)\n",
        "\n",
        "    merged_df.to_csv(os.path.join(merged_save_dir, f\"{state}-{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n",
        "    if save_training:\n",
        "      save_dir = merged_save_dir #Use the local directory if not in Google Colab\n",
        "      file_path = os.path.join(save_dir, f\"{state}-{target_column}-{dataset_name}.csv\")\n",
        "      merged_df.to_csv(file_path, index=False)\n",
        "      print(f\"Saved file at: {file_path}\")\n",
        "\n",
        "      # try:\n",
        "      #   from google.colab import drive\n",
        "      #   drive.mount('/content/drive')\n",
        "      #   save_dir = '/content/drive/My Drive/RunModels' #Your Google Drive path\n",
        "      #   check_directory(save_dir)\n",
        "\n",
        "      # except ImportError:\n",
        "      #   save_dir = merged_save_dir #Use the local directory if not in Google Colab\n",
        "\n",
        "      # file_path = os.path.join(save_dir, f\"{state}-{target_column}-{dataset_name}.csv\")\n",
        "      # merged_df.to_csv(file_path, index=False)\n",
        "      # print(f\"Saved file at: {file_path}\")\n",
        "\n",
        "      merged_df.to_csv(os.path.join(merged_save_dir, f\"{state}-{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n",
        "if not save_training:\n",
        "      print(f\"Since save_training is false no files are currently saved.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CoPB-9qx1n7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105048e8-0ebe-4188-9bc8-4f44f6cd069b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '../process/bees/states-2022_increase-bees' created successfully.\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AK-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AZ-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AR-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CO-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/DE-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/FL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/GA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/HI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ID-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/KS-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/KY-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/LA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ME-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MD-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MS-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MO-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NE-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NV-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NH-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NJ-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NM-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NY-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NC-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ND-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OH-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OK-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OR-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/PA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/RI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/SC-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/SD-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/TN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/TX-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/UT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/VT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/VA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WV-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WY-2022_increase-bees.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP: Integrate separate state data into one, return the full dataset csv\n",
        "# If save_training=True, your files will reside in the \"output\" folder to the left.\n",
        "# Hit the refresh icon above your folder list to the left.\n",
        "save_dir = full_save_dir  # Use the local directory if save_training is True\n",
        "\n",
        "check_directory(save_dir)\n",
        "\n",
        "dataframes = []\n",
        "csv_directory = f\"../process/{dataset_name}/states-{target_column}-{dataset_name}\"\n",
        "csv_files = os.listdir(csv_directory)\n",
        "for csv_file in csv_files:\n",
        "    if csv_file.endswith('.csv'):\n",
        "        dataframes.append(pd.read_csv(os.path.join(csv_directory, csv_file)))\n",
        "\n",
        "integrated_df = pd.concat(dataframes, ignore_index=True)\n",
        "df = integrated_df\n",
        "\n",
        "if save_training:\n",
        "  save_dir = full_save_dir #Use the local directory if not in Google Colab\n",
        "  file_path = os.path.join(save_dir, f\"{target_column}-{dataset_name}.csv\")\n",
        "  integrated_df.to_csv(file_path, index=False)\n",
        "  print(f\"Saved file at: {file_path}\")\n",
        "    # try:\n",
        "    #   from google.colab import drive\n",
        "    #   drive.mount('/content/drive', force_remount=True)\n",
        "    #   save_dir = '/content/drive/My Drive/RunModels' #Your Google Drive path\n",
        "    #   check_directory(save_dir)\n",
        "    # except ImportError:\n",
        "    #   save_dir = full_save_dir #Use the local directory if not in Google Colab\n",
        "\n",
        "  file_path = os.path.join(save_dir, f\"{target_column}-{dataset_name}.csv\")\n",
        "  integrated_df.to_csv(file_path, index=False)\n",
        "  print(f\"Saved file at: {file_path}\")\n",
        "  #integrated_df.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7rpuU75xWKp",
        "outputId": "fa146412-5fe5-4357-a7f1-f9cb4b3b2683"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '../output/bees/training' already exists.\n",
            "Saved file at: ../output/bees/training/2022_increase-bees.csv\n",
            "Saved file at: ../output/bees/training/2022_increase-bees.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2SxJJr6-x9gO"
      },
      "outputs": [],
      "source": [
        "# Train the model and get the test report\n",
        "def train_model(model, X_train, y_train, X_test, y_test, over_sample):\n",
        "\n",
        "    if over_sample:\n",
        "        sm = SMOTE(random_state = 2)\n",
        "        X_train, y_train = sm.fit_resample(X_train, y_train.ravel())\n",
        "        print(\"Oversampling Done for Training Data.\")\n",
        "\n",
        "    model = model.fit(X_train, y_train)\n",
        "    print(\"Model Fitted Successfully.\")\n",
        "\n",
        "    # calculating y_pred\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "    #roc_auc score\n",
        "    roc_auc = round(roc_auc_score(y_test, y_pred_prob[:, 1]), 2)\n",
        "    print(f\"\\033[1mROC-AUC Score\\033[0m \\t\\t: {roc_auc*100} %\")\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1], pos_label=1)\n",
        "\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "\n",
        "    ix = np.argmax(gmeans)\n",
        "\n",
        "    print('\\033[1mBest Threshold\\033[0m \\t\\t: %.3f \\n\\033[1mG-Mean\\033[0m \\t\\t\\t: %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    best_threshold_num = round(thresholds[ix], 3)\n",
        "\n",
        "    gmeans_num = round(gmeans[ix], 3)\n",
        "\n",
        "    y_pred = (y_pred > thresholds[ix])\n",
        "\n",
        "    #ccuracy score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_num = f\"{accuracy * 100:.1f}\"\n",
        "\n",
        "    print(\"\\033[1mModel Accuracy\\033[0m \\t\\t:\", round(accuracy,2,)*100, \"%\")\n",
        "    print(\"\\033[1m\\nClassification Report:\\033[0m\")\n",
        "\n",
        "    #Generate classification report for display and in dictionary for furture report generation\n",
        "    cfc_report = classification_report(y_test, y_pred)\n",
        "    cfc_report_dict = classification_report(y_test, y_pred, output_dict= True)\n",
        "    print(cfc_report)\n",
        "\n",
        "    return model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict\n",
        "\n",
        "# Train the specified model, impute the nan values, and save the trained model as well as the feature-target report\n",
        "def train(model_name, target_column, dataset_name, X_train, y_train, X_test, y_test, report_gen, all_model_list, valid_report_list, over_sample=False, model_saving=True, random_state=42):\n",
        "    assert model_name in all_model_list\n",
        "\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train_imputed = imputer.fit_transform(X_train)\n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    if model_name == \"LogisticRegression\":\n",
        "        model = LogisticRegression(max_iter=10000, random_state=random_state)\n",
        "    elif model_name == \"SVM\":\n",
        "        model = SVC(random_state=random_state,probability=True)\n",
        "    elif model_name == \"MLP\":\n",
        "        model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=1000, random_state=random_state)\n",
        "    elif model_name == \"RandomForest\":\n",
        "        model = RandomForestClassifier(n_jobs=3, n_estimators=1000, criterion=\"gini\", random_state=random_state)\n",
        "        model_fullname = \"Random Forest\"\n",
        "    elif model_name == \"XGBoost\":\n",
        "        model = xgb.XGBClassifier(random_state=random_state)\n",
        "        model_fullname = \"XGBoost\"\n",
        "    else:\n",
        "        raise Exception\n",
        "\n",
        "    if model_name == \"XGBoost\":\n",
        "        model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict = train_model(model, X_train, y_train, X_test, y_test, over_sample) # No need to impute nan values for XGBoost\n",
        "\n",
        "    else:\n",
        "        model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict = train_model(model, X_train_imputed, y_train, X_test_imputed, y_test, over_sample)\n",
        "\n",
        "\n",
        "    save_dir = f\"../output/{dataset_name}/saved\"\n",
        "    check_directory(save_dir)\n",
        "\n",
        "    if model_saving:\n",
        "        if model_name == \"XGBoost\":\n",
        "            save_model(model, None, target_column, dataset_name, model_name, save_dir) # No need to impute nan values for XGBoost\n",
        "        else:\n",
        "            save_model(model, imputer, target_column, dataset_name, model_name, save_dir)\n",
        "\n",
        "    if report_gen:\n",
        "        if model_name in valid_report_list:\n",
        "            if model_name == \"RandomForest\":\n",
        "                importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': model.feature_importances_})\n",
        "                report = importance_df.sort_values(by='Importance', ascending=False)\n",
        "            elif model_name == \"XGBoost\":\n",
        "                importance_df = pd.DataFrame(list(model.get_booster().get_score().items()), columns=[\"Feature\",\"Importance\"])\n",
        "                report = importance_df.sort_values(by='Importance', ascending=False)\n",
        "            else:\n",
        "                raise Exception\n",
        "\n",
        "            report[\"Feature_Name\"] = report[\"Feature\"].apply(report_modify)\n",
        "            report = report.reindex(columns=[\"Feature\",\"Feature_Name\",\"Importance\"])\n",
        "            report.to_csv(os.path.join(save_dir, f\"{target_column}-{dataset_name}-report-{model_name}.csv\"), index=False)\n",
        "        else:\n",
        "            report = None\n",
        "            print(\"No Valid Report for Current Model\")\n",
        "\n",
        "    return model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num\n",
        "\n",
        "\n",
        "\n",
        "# Save the trained model and nan-value imputer\n",
        "def save_model(model, imputer, target_column, dataset_name, model_name, save_dir):\n",
        "    data = {\n",
        "    \"model\": model,\n",
        "    \"imputer\": imputer\n",
        "    }\n",
        "    with open(os.path.join(save_dir, f\"{target_column}-{dataset_name}-trained-{model_name}.pkl\"), 'wb') as file:\n",
        "        pickle.dump(data, file)\n",
        "\n",
        "# Modify the feature-importance report by adding an industry-correspondence introduction column\n",
        "def report_modify(value):\n",
        "    splitted = value.split(\"-\")\n",
        "    if splitted[0] in [\"Emp\",\"Est\",\"Pay\"]:\n",
        "        try:\n",
        "            modified = splitted[0]+\"-\"+INDUSTRIES_DICT[splitted[1]]+\"-\"+splitted[2]\n",
        "        except:\n",
        "            modified = value\n",
        "        return modified\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "\n",
        "def report_generator(cfc_report_dict, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num):\n",
        "    #transfrom report from dictionary to df\n",
        "    df_report = pd.DataFrame.from_dict(cfc_report_dict).transpose()\n",
        "\n",
        "    #adjust data display format for md and yaml\n",
        "    df_report['support'] = df_report['support'].astype(int)\n",
        "    df_report.iloc[:, 0:3] = df_report.iloc[:, 0:3].round(2)\n",
        "    df_report.iloc[2,0] = \" \"\n",
        "    df_report.iloc[2,1] = \" \"\n",
        "    df_report.iloc[2,3] = df_report.iloc[3,3]\n",
        "\n",
        "    #edit roc_auc format\n",
        "    roc_auc = roc_auc *100\n",
        "\n",
        "    #covert numpy float to python float for yaml display\n",
        "    roc_auc = roc_auc.item()\n",
        "    best_threshold_num = best_threshold_num.item()\n",
        "    gmeans_num = gmeans_num.item()\n",
        "\n",
        "    #markdown file content\n",
        "    markdown_content = f\"\"\"\n",
        "## {model_fullname} Accuracy\n",
        "\n",
        "**ROC-AUC Score:** {roc_auc}% &nbsp;&nbsp; **Best Threshold:** {best_threshold_num} &nbsp;&nbsp; **G-Mean:** {gmeans_num} &nbsp;&nbsp; **Model Accuracy:** {accuracy_num}%\n",
        "\n",
        "                    Precision   Recall      F1-Score    Support\n",
        "\n",
        "    0               {df_report.iloc[0,0]}        {df_report.iloc[0,1]}        {df_report.iloc[0,2]}        {df_report.iloc[0,3]}\n",
        "    1               {df_report.iloc[1,0]}        {df_report.iloc[1,1]}        {df_report.iloc[1,2]}        {df_report.iloc[1,3]}\n",
        "\n",
        "    Accuracy                                {df_report.iloc[2,2]}        {df_report.iloc[3,3]}\n",
        "    Macro Avg       {df_report.iloc[3,0]}        {df_report.iloc[3,1]}        {df_report.iloc[3,2]}        {df_report.iloc[3,3]}\n",
        "    Weighted Avg    {df_report.iloc[4,0]}        {df_report.iloc[4,1]}        {df_report.iloc[4,2]}        {df_report.iloc[3,3]}\n",
        "\"\"\"\n",
        "\n",
        "    #yaml output dictionary\n",
        "    report_dict = {\n",
        "    \"model_fullname\": model_fullname,\n",
        "    \"roc_auc\": roc_auc,\n",
        "    \"best_threshold_num\": best_threshold_num,\n",
        "    \"gmeans_num\": gmeans_num,\n",
        "    \"accuracy_num\": accuracy_num,\n",
        "    \"classification_report\": df_report.to_dict(orient=\"index\")\n",
        "    }\n",
        "\n",
        "    with open(f'{model_name}_accuracy.md','w') as markdown_file:\n",
        "        markdown_file.write(markdown_content)\n",
        "\n",
        "    with open(f'{model_name}_accuracy.yaml', \"w\") as f:\n",
        "        yaml.dump(report_dict, f, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bglCZfAox9gP"
      },
      "outputs": [],
      "source": [
        "# Read the integrated full dataset and do the train-test splitting and save the splitted files\n",
        "if save_training:\n",
        "  integrated_df = pd.read_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}.csv\"))\n",
        "\n",
        "X_total, y_total = df.iloc[:, feature_start_idx:], df.iloc[:, target_idx] #X_total, y_total = integrated_df.iloc[:, feature_start_idx:], integrated_df.iloc[:, target_idx]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.2, random_state=random_state)\n",
        "X_train.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-X-train.csv\"), index=False)\n",
        "X_test.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-X-test.csv\"), index=False)\n",
        "y_train.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-y-train.csv\"), index=False)\n",
        "y_test.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-y-test.csv\"), index=False)\n",
        "\n",
        "if save_training:\n",
        "  file_path = os.path.join(full_save_dir, f\"X_train.csv\")\n",
        "  X_train.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"X_test.csv\")\n",
        "  X_test.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"y_train.csv\")\n",
        "  y_train.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"y_test.csv\")\n",
        "  y_test.to_csv(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zQkPjCR7C0q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpmeBMiYx9gP"
      },
      "source": [
        "Model training, testing and results saving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vqiy1m6-x9gQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba2f214-c360-490a-c632-81970e855ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Fitted Successfully.\n",
            "\u001b[1mROC-AUC Score\u001b[0m \t\t: 56.00000000000001 %\n",
            "\u001b[1mBest Threshold\u001b[0m \t\t: 0.639 \n",
            "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.551\n",
            "\u001b[1mModel Accuracy\u001b[0m \t\t: 65.0 %\n",
            "\u001b[1m\n",
            "Classification Report:\u001b[0m\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.51      0.11      0.18       198\n",
            "         1.0       0.67      0.94      0.78       372\n",
            "\n",
            "    accuracy                           0.65       570\n",
            "   macro avg       0.59      0.53      0.48       570\n",
            "weighted avg       0.61      0.65      0.57       570\n",
            "\n",
            "Directory '../output/bees/saved' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Training Random Forest\n",
        "model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num= train(\"RandomForest\", target_column, dataset_name, X_train, y_train, X_test, y_test,\n",
        "      report_gen=True, all_model_list=all_model_list, valid_report_list=valid_report_list, over_sample=False, model_saving=True, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate markdown and yaml file\n",
        "# Results will appear in the content folder to the left\n",
        "report_generator(cfc_report_dict, model_fullname, \"RandomForest\", gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
      ],
      "metadata": {
        "id": "sKhOoFlz2rwj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WmFTVDnjx9gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6fc32c1-5205-4867-9ada-6028bc924af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Fitted Successfully.\n",
            "\u001b[1mROC-AUC Score\u001b[0m \t\t: 51.0 %\n",
            "\u001b[1mBest Threshold\u001b[0m \t\t: 0.798 \n",
            "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.516\n",
            "\u001b[1mModel Accuracy\u001b[0m \t\t: 56.99999999999999 %\n",
            "\u001b[1m\n",
            "Classification Report:\u001b[0m\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.22      0.26       198\n",
            "         1.0       0.65      0.76      0.70       372\n",
            "\n",
            "    accuracy                           0.57       570\n",
            "   macro avg       0.49      0.49      0.48       570\n",
            "weighted avg       0.53      0.57      0.55       570\n",
            "\n",
            "Directory '../output/bees/saved' already exists.\n"
          ]
        }
      ],
      "source": [
        "# Generating dummy values to handle the categorical columns: 'Population-2018', 'Population-2019', 'Population-2020'\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "#Train XGBoost model\n",
        "model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num  = train(\"XGBoost\", target_column, dataset_name, X_train, y_train, X_test, y_test,\n",
        "      report_gen=True, all_model_list=all_model_list, valid_report_list=valid_report_list, over_sample=False, model_saving=True, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4jQDQdxbx9gS"
      },
      "outputs": [],
      "source": [
        "# Generate Report for XGBoost\n",
        "report_generator(cfc_report_dict, \"XGBoost\", \"XGBoost\", gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2FMxCN94eqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}