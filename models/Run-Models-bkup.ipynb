{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Models (includes RandomForest and XGBoost)\n",
        "\n",
        "Documentation\n",
        "https://model.earth/RealityStream  \n",
        "https://model.earth/RealityStream/input/industries backed-up to Run-Models-bkup.ipynb\n",
        "\n",
        "DONE Aashish: Used Pandas for integrated_df (became df) for save_training = False.  \n",
        "DONE Loren: Loaded parameters.yaml and saved locally for customization.  \n",
        "https://chatgpt.com/share/e4a2ee73-ab74-4551-9868-37b9b5b6b359  \n",
        "\n",
        "\n",
        "**TO DO Lily:** Reactivate these two lines after inserting all the parameters into the incoming bees features path from parameters.yaml. Then test that panels 15 and 16 work.  \n",
        "if param.targets.path: # Override with value from yaml  \n",
        "    target_url = param.targets.path\n",
        "\n",
        "DONE Ivy: In the same panel as each accuracy report, call a new function called displayModelHeader to display the model name (as a bold header) and the file paths for features and targets above the report.\n",
        "\n",
        "DONE Ivy: Show the parameter values below each path at the top of each accuracy report. So under the Feature path we'd have:  \n",
        "startyear: 2017, endyear: 2021, naics: [6], state: ME\n",
        "\n",
        "Yanquig: Add support for multiple states. After running the third panel, you can edit the custom yaml on the right to set state: CT, ME, MA, NH, RI, VT.  Then add a loop that runs when there are multiple states. We'll add a file called parameters-new-england.yaml in the root of the RealityStream repo with the six states as features.states. Load here and add python to loop through the states.\n",
        "\n",
        "Ronan: Edit the parameters to pull in one of the new targets and join on the county Fips column. Send me the yaml you use or add a new file to the root of RealityStream. Add a path parameter that pulls from \"all-years\" which are generated by our [Industry Features CoLab](https://colab.research.google.com/drive/1HJnuilyEFjBpZLrgxDa4S0diekwMeqnh?usp=sharing). All years on GitHub:  \n",
        "https://github.com/ModelEarth/community-timelines/tree/main/training/all-years\n",
        "\n",
        "TO DO: Load blinks/parameters-blinks.yaml and use target.column to limit to y column!\n",
        "\n",
        "TO DO: Load 1 of these 4 bee targets using parameters.yaml setting.\n",
        "https://github.com/ModelEarth/RealityStream/tree/main/input/bees/targets  \n",
        "\n",
        "TO DO: Setting model_name = \"XGBoost\" resulted in the error:\n",
        "\n",
        "ValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Population-2018: object, Population-2019: object, Population-2020: object\n",
        "\n",
        "Akshay: Load parameters.yaml into Streamlit\n",
        "https://reality.streamlit.app/?parameters=https://raw.githubusercontent.com/ModelEarth/RealityStream/main/parameters.yaml\n",
        "\n",
        "TO DO: Load common util files (from GitHub) into both Google CoLab and RealityStream Streamlit app.py."
      ],
      "metadata": {
        "id": "jxZiI7xcrT4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtFKCS4LkOzN"
      },
      "outputs": [],
      "source": [
        "save_training = True  # When False, Pandas is used.\n",
        "\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import yaml\n",
        "import requests\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default parameters file and local path to save at.\n",
        "# After running you can edit parameters that appear to the right.\n",
        "# Coming soon:\n",
        "# You can change the bees year in the targets.path to: 2007, 2012, 1017, 2022\n",
        "# TO DO: Changing the year in the bees target does not work yet. Make updates to other panels.\n",
        "parametersSource = \"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/parameters.yaml\"\n",
        "\n",
        "# Blinks - Under development by Kelvin\n",
        "# parametersSource = \"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/blinks/parameters-blinks.yaml\"\n",
        "\n",
        "importNewParameters = True\n",
        "overwriteExistingParameter = False\n",
        "localParametersPath = '/content/parametersLocal.yaml'\n",
        "\n",
        "# Fetch the parameters from the source URL\n",
        "response = requests.get(parametersSource)\n",
        "parametersSourceData = yaml.safe_load(response.content)\n",
        "\n",
        "# Function to merge dictionaries\n",
        "def merge_dicts(source, local, import_new, overwrite_existing):\n",
        "    for key, value in source.items():\n",
        "        if key in local:\n",
        "            if isinstance(value, dict) and isinstance(local[key], dict):\n",
        "                merge_dicts(value, local[key], import_new, overwrite_existing)\n",
        "            elif overwrite_existing:\n",
        "                local[key] = value\n",
        "        else:\n",
        "            if import_new:\n",
        "                local[key] = value\n",
        "\n",
        "class DictToObject:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            if isinstance(value, dict):\n",
        "                value = DictToObject(value)\n",
        "            self.__dict__[key] = value\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.__dict__[key]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        self.__dict__[key] = value\n",
        "\n",
        "# Load local parameters if they exist\n",
        "if os.path.exists(localParametersPath):\n",
        "    with open(localParametersPath, 'r') as file:\n",
        "        parametersLocalData = yaml.safe_load(file)\n",
        "else:\n",
        "    parametersLocalData = {}\n",
        "\n",
        "# Merge parameters according to specified rules\n",
        "merge_dicts(parametersSourceData, parametersLocalData, importNewParameters, overwriteExistingParameter)\n",
        "\n",
        "# Save the merged parameters locally\n",
        "with open(localParametersPath, 'w') as file:\n",
        "    yaml.dump(parametersLocalData, file)\n",
        "\n",
        "# Display local parameters file in the left side of Colab\n",
        "from google.colab import files\n",
        "files.view(localParametersPath)"
      ],
      "metadata": {
        "id": "LRqQNpac3jeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "640608b2-1817-42a4-ce63-5196f45d1430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/parametersLocal.yaml\")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Parameters\n",
        "# Load local parameters and print below.\n",
        "\n",
        "import yaml\n",
        "\n",
        "localParametersPath = '/content/parametersLocal.yaml'\n",
        "\n",
        "# Load parameters from the local file\n",
        "with open(localParametersPath, 'r') as file:\n",
        "    param_dict = yaml.safe_load(file)\n",
        "\n",
        "# Convert dictionary to an object with dot notation access\n",
        "param = DictToObject(param_dict)\n",
        "\n",
        "# Print the parameters\n",
        "def print_param(obj, indent=0):\n",
        "    for key in obj.__dict__.keys():\n",
        "        value = getattr(obj, key)\n",
        "        if isinstance(value, DictToObject):\n",
        "            print(' ' * indent + f\"{key}:\")\n",
        "            print_param(value, indent + 2)\n",
        "        else:\n",
        "            print(' ' * indent + f\"{key}: {value}\")\n",
        "\n",
        "# Also not in use yet, these will only be used if parametersLocal.yaml omits.\n",
        "features_data = param['features']['data'] # \"industries\"\n",
        "features_path = param['features']['path'] # \"https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\"\n",
        "targets_data  = param['targets']['data'] # \"bees\"\n",
        "targets_path  = param['targets']['path'] # \"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\"\n",
        "\n",
        "print_param(param)\n",
        "\n",
        "print(\"\\nparam.features.path:\", param.features.path)\n",
        "print(\"param.targets.path:\", param.targets.path)\n",
        "print(\"param.features.state:\", param.features.state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alauCxr5yHF7",
        "outputId": "1c184ad6-7f8f-48fa-db78-aa03d097f1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features:\n",
            "  data: industries\n",
            "  endyear: 2021\n",
            "  naics: [6]\n",
            "  path: https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\n",
            "  startyear: 2017\n",
            "  state: ME\n",
            "models: rbf\n",
            "targets:\n",
            "  data: bees\n",
            "  path: https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\n",
            "\n",
            "param.features.path: https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\n",
            "param.targets.path: https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\n",
            "param.features.state: ME\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: Setting model_name = \"XGBoost\" resulted in the error:\n",
        "# ValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Population-2018: object, Population-2019: object, Population-2020: object\n",
        "\n",
        "# TO DO: These are in use, replace with parameters\n",
        "\n",
        "dataset_name = \"bees\"  # TO DO: eliminate since features and targets will differ.\n",
        "model_name = \"RandomForest\"  # Specify the model to be trained\n",
        "all_model_list = [\"LogisticRegression\", \"SVM\", \"MLP\", \"RandomForest\", \"XGBoost\"]  # All usable models\n",
        "assert model_name in all_model_list\n",
        "valid_report_list = [\"RandomForest\", \"XGBoost\"]  # All valid models to generate feature-importance report\n",
        "\n",
        "random_state = 42  # Specify random state\n",
        "\n",
        "# Feature related information:\n",
        "country = \"US\"\n",
        "years = range(2017, 2022)\n",
        "naics_level = 2\n",
        "naics_list = [2, 4, 6]\n",
        "assert naics_level in naics_list\n",
        "\n",
        "# Target related information:\n",
        "target_url = f\"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/{dataset_name}/targets/{dataset_name}-targets.csv\"\n",
        "#if param.targets.path: # Override with value from yaml\n",
        "  #target_url = param.targets.path\n",
        "target_df = pd.read_csv(target_url)  # Get the target csv\n",
        "\n",
        "if dataset_name == \"bees\":  # Eliminate these lines after switching to parameters.yaml settings\n",
        "    target_column = '2022_increase'  # Specify the target column\n",
        "    target_list = ['2007_increase', '2012_increase', '2017_increase', '2022_increase']  # Specify all usable target columns\n",
        "    target_list.remove(target_column)  # Drop the one we are interested in\n",
        "\n",
        "year_list = [\"2002\", \"2007\", \"2012\", \"2017\", \"2022\"]\n",
        "drop_list = ['Unnamed: 0', 'Name', 'State', 'State ANSI', 'County ANSI', \"Ag District\", \"Ag District Code\"]\n",
        "all_drop_list = drop_list + target_list + year_list  # Drop all columns that can affect the training procedure or are not related\n",
        "\n",
        "feature_start_idx = 3  # Specify the starting column index in dataset csv for features, where first few columns are for target and id related stuff\n",
        "target_idx = 0  # Specify the column index for target\n",
        "\n",
        "# Directory Information:\n",
        "merged_save_dir = f\"../process/{dataset_name}/states-{target_column}-{dataset_name}\"  # Specify the saving dir for state-separate dataset\n",
        "full_save_dir = f\"../output/{dataset_name}/training\"  # Specify the saving dir for the integrated dataset\n"
      ],
      "metadata": {
        "id": "Z12cWU4y09on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdUt24w63WDa"
      },
      "outputs": [],
      "source": [
        "# STEP: Get Dictionaries for states and industries\n",
        "STATE_DICT = {\n",
        "    \"AL\": \"ALABAMA\",\"AK\": \"ALASKA\",\"AZ\": \"ARIZONA\",\"AR\": \"ARKANSAS\",\"CA\": \"CALIFORNIA\",\"CO\": \"COLORADO\",\"CT\": \"CONNECTICUT\",\"DE\": \"DELAWARE\",\"FL\": \"FLORIDA\",\"GA\": \"GEORGIA\",\"HI\": \"HAWAII\",\"ID\": \"IDAHO\",\"IL\": \"ILLINOIS\",\"IN\": \"INDIANA\",\"IA\": \"IOWA\",\"KS\": \"KANSAS\",\"KY\": \"KENTUCKY\",\"LA\": \"LOUISIANA\",\"ME\": \"MAINE\",\"MD\": \"MARYLAND\",\"MA\": \"MASSACHUSETTS\",\"MI\": \"MICHIGAN\",\"MN\": \"MINNESOTA\",\"MS\": \"MISSISSIPPI\",\"MO\": \"MISSOURI\",\"MT\": \"MONTANA\",\"NE\": \"NEBRASKA\",\"NV\": \"NEVADA\",\"NH\": \"NEW HAMPSHIRE\",\"NJ\": \"NEW JERSEY\",\"NM\": \"NEW MEXICO\",\"NY\": \"NEW YORK\",\"NC\": \"NORTH CAROLINA\",\"ND\": \"NORTH DAKOTA\",\"OH\": \"OHIO\",\"OK\": \"OKLAHOMA\",\"OR\": \"OREGON\",\"PA\": \"PENNSYLVANIA\",\"RI\": \"RHODE ISLAND\",\"SC\": \"SOUTH CAROLINA\",\"SD\": \"SOUTH DAKOTA\",\"TN\": \"TENNESSEE\",\"TX\": \"TEXAS\",\"UT\": \"UTAH\",\"VT\": \"VERMONT\",\"VA\": \"VIRGINIA\",\"WA\": \"WASHINGTON\",\"WV\": \"WEST VIRGINIA\",\"WI\": \"WISCONSIN\",\"WY\": \"WYOMING\"\n",
        "}\n",
        "try:\n",
        "    industries_df = pd.read_csv(f\"https://raw.githubusercontent.com/ModelEarth/community-data/master/{country.lower()}/id_lists/naics{naics_level}.csv\",header=None)\n",
        "    INDUSTRIES_DICT = industries_df.set_index(0).to_dict()[1]\n",
        "except:\n",
        "    INDUSTRIES_DICT = dict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Not using, we'll load .py from a GitHub link instead.\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8MwzUBj6kPq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv_AUQwjnrkN"
      },
      "outputs": [],
      "source": [
        "# STEP: Create Functions\n",
        "def rename_columns(df, year):\n",
        "    rename_mapping = {}\n",
        "    for column in df.columns:\n",
        "      if column not in df.columns[:2]:\n",
        "          new_column_name = column + f'-{year}'\n",
        "          rename_mapping[column] = new_column_name\n",
        "\n",
        "    df.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "def check_directory(directory_path): # Check whether the given directory exists, if not, then create it\n",
        "    if not os.path.exists(directory_path):\n",
        "        try:\n",
        "            os.makedirs(directory_path)\n",
        "            print(f\"Directory '{directory_path}' created successfully.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error creating directory '{directory_path}': {e}\")\n",
        "    else:\n",
        "        print(f\"Directory '{directory_path}' already exists.\")\n",
        "    return directory_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP: Merge feature and target data\n",
        "# If save_training=True, your files will reside in the \"process\" folder to the left.\n",
        "# Hit the refresh icon above your folder list to the left.\n",
        "if save_training:\n",
        "    save_dir = merged_save_dir  # Save in the local directory if save_training is True\n",
        "\n",
        "check_directory(save_dir)\n",
        "\n",
        "# State-separately, for each state, merging industry features and target on Fips value and County Name, return the merged csv\n",
        "\n",
        "for state in STATE_DICT:\n",
        "    data = {}\n",
        "    for year in years:\n",
        "        url = f\"https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics_level}/{country}/counties/{year}/{country}-{state}-training-naics{naics_level}-counties-{year}.csv\"\n",
        "        data[year] = pd.read_csv(url)\n",
        "        rename_columns(data[year], year)\n",
        "\n",
        "    merged_df_feature = pd.merge(data[2017], data[2018], on=['Fips', 'Name'], how='inner')\n",
        "    for year in range(2019, 2022):\n",
        "        merged_df_feature = pd.merge(merged_df_feature, data[year], on=['Fips', 'Name'], how='inner')\n",
        "\n",
        "    cols = merged_df_feature.columns.tolist()\n",
        "    cols = cols[:2] + sorted(cols[2:])\n",
        "    merged_df_feature = merged_df_feature[cols].rename(columns={\"Name\": \"County\"})\n",
        "\n",
        "    merged_df = pd.merge(merged_df_feature, target_df[target_df[\"State\"] == STATE_DICT[state]], on=[\"Fips\", \"County\"], how=\"inner\")\n",
        "    merged_df.drop(columns=all_drop_list, axis=1, inplace=True)\n",
        "\n",
        "    target = merged_df.iloc[:, -1]\n",
        "    merged_df.drop(columns=[target_column], axis=1, inplace=True)\n",
        "    merged_df.insert(0, 'target', target)\n",
        "\n",
        "    merged_df.to_csv(os.path.join(merged_save_dir, f\"{state}-{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n",
        "    if save_training:\n",
        "      save_dir = merged_save_dir #Use the local directory if not in Google Colab\n",
        "      file_path = os.path.join(save_dir, f\"{state}-{target_column}-{dataset_name}.csv\")\n",
        "      merged_df.to_csv(file_path, index=False)\n",
        "      print(f\"Saved file at: {file_path}\")\n",
        "\n",
        "      # try:\n",
        "      #   from google.colab import drive\n",
        "      #   drive.mount('/content/drive')\n",
        "      #   save_dir = '/content/drive/My Drive/RunModels' #Your Google Drive path\n",
        "      #   check_directory(save_dir)\n",
        "\n",
        "      # except ImportError:\n",
        "      #   save_dir = merged_save_dir #Use the local directory if not in Google Colab\n",
        "\n",
        "      # file_path = os.path.join(save_dir, f\"{state}-{target_column}-{dataset_name}.csv\")\n",
        "      # merged_df.to_csv(file_path, index=False)\n",
        "      # print(f\"Saved file at: {file_path}\")\n",
        "\n",
        "      merged_df.to_csv(os.path.join(merged_save_dir, f\"{state}-{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n",
        "if not save_training:\n",
        "      print(f\"Since save_training is false no files are currently saved.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CoPB-9qx1n7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73352d8-5cb8-4ba6-a4af-37509112063a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '../process/bees/states-2022_increase-bees' already exists.\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AK-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AZ-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/AR-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CO-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/CT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/DE-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/FL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/GA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/HI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ID-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IL-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/IA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/KS-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/KY-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/LA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ME-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MD-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MS-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MO-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/MT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NE-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NV-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NH-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NJ-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NM-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NY-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/NC-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/ND-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OH-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OK-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/OR-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/PA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/RI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/SC-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/SD-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/TN-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/TX-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/UT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/VT-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/VA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WA-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WV-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WI-2022_increase-bees.csv\n",
            "Saved file at: ../process/bees/states-2022_increase-bees/WY-2022_increase-bees.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP: Integrate separate state data into one, return the full dataset csv\n",
        "# If save_training=True, your files will reside in the \"output\" folder to the left.\n",
        "# Hit the refresh icon above your folder list to the left.\n",
        "save_dir = full_save_dir  # Use the local directory if save_training is True\n",
        "\n",
        "check_directory(save_dir)\n",
        "\n",
        "dataframes = []\n",
        "csv_directory = f\"../process/{dataset_name}/states-{target_column}-{dataset_name}\"\n",
        "csv_files = os.listdir(csv_directory)\n",
        "for csv_file in csv_files:\n",
        "    if csv_file.endswith('.csv'):\n",
        "        dataframes.append(pd.read_csv(os.path.join(csv_directory, csv_file)))\n",
        "\n",
        "integrated_df = pd.concat(dataframes, ignore_index=True)\n",
        "df = integrated_df\n",
        "\n",
        "if save_training:\n",
        "  save_dir = full_save_dir #Use the local directory if not in Google Colab\n",
        "  file_path = os.path.join(save_dir, f\"{target_column}-{dataset_name}.csv\")\n",
        "  integrated_df.to_csv(file_path, index=False)\n",
        "  print(f\"Saved file at: {file_path}\")\n",
        "    # try:\n",
        "    #   from google.colab import drive\n",
        "    #   drive.mount('/content/drive', force_remount=True)\n",
        "    #   save_dir = '/content/drive/My Drive/RunModels' #Your Google Drive path\n",
        "    #   check_directory(save_dir)\n",
        "    # except ImportError:\n",
        "    #   save_dir = full_save_dir #Use the local directory if not in Google Colab\n",
        "\n",
        "  file_path = os.path.join(save_dir, f\"{target_column}-{dataset_name}.csv\")\n",
        "  integrated_df.to_csv(file_path, index=False)\n",
        "  print(f\"Saved file at: {file_path}\")\n",
        "  #integrated_df.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}.csv\"), index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "M7rpuU75xWKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01031cf9-6b72-4d6a-826c-d93b17785be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '../output/bees/training' already exists.\n",
            "Saved file at: ../output/bees/training/2022_increase-bees.csv\n",
            "Saved file at: ../output/bees/training/2022_increase-bees.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SxJJr6-x9gO"
      },
      "outputs": [],
      "source": [
        "#Display bald model header on top of the report including model name and feature/target path\n",
        "def displayModelHeader(featurePath,targetPath, model):\n",
        "  print(f\"\\033[1mModel: {model}\\033\\nFeature path:{featurePath}\\nTarget path: {targetPath}\")\n",
        "  print(f\"startyear: {param.features.startyear}, endyear: {param.features.endyear}, naics:{param.features.naics}, state: {param.features.state}\")\n",
        "\n",
        "# Train the model and get the test report\n",
        "def train_model(model, X_train, y_train, X_test, y_test, over_sample):\n",
        "\n",
        "    if over_sample:\n",
        "        sm = SMOTE(random_state = 2)\n",
        "        X_train, y_train = sm.fit_resample(X_train, y_train.ravel())\n",
        "        print(\"Oversampling Done for Training Data.\")\n",
        "\n",
        "\n",
        "    model = model.fit(X_train, y_train)\n",
        "    print(\"Model Fitted Successfully.\")\n",
        "\n",
        "    # calculating y_pred\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "    #roc_auc score\n",
        "    roc_auc = round(roc_auc_score(y_test, y_pred_prob[:, 1]), 2)\n",
        "    print(f\"\\033[1mROC-AUC Score\\033[0m \\t\\t: {roc_auc*100} %\")\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1], pos_label=1)\n",
        "\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "\n",
        "    ix = np.argmax(gmeans)\n",
        "\n",
        "    print('\\033[1mBest Threshold\\033[0m \\t\\t: %.3f \\n\\033[1mG-Mean\\033[0m \\t\\t\\t: %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    best_threshold_num = round(thresholds[ix], 3)\n",
        "\n",
        "    gmeans_num = round(gmeans[ix], 3)\n",
        "\n",
        "    y_pred = (y_pred > thresholds[ix])\n",
        "\n",
        "    #ccuracy score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_num = f\"{accuracy * 100:.1f}\"\n",
        "\n",
        "    print(\"\\033[1mModel Accuracy\\033[0m \\t\\t:\", round(accuracy,2,)*100, \"%\")\n",
        "    print(\"\\033[1m\\nClassification Report:\\033[0m\")\n",
        "\n",
        "    #Generate classification report for display and in dictionary for future report generation\n",
        "    cfc_report = classification_report(y_test, y_pred)\n",
        "    cfc_report_dict = classification_report(y_test, y_pred, output_dict= True)\n",
        "    print(cfc_report)\n",
        "\n",
        "    return model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict\n",
        "\n",
        "# Train the specified model, impute the nan values, and save the trained model as well as the feature-target report\n",
        "def train(featurePath,targetPath, model_name, target_column, dataset_name, X_train, y_train, X_test, y_test, report_gen, all_model_list, valid_report_list, over_sample=False, model_saving=True, random_state=42):\n",
        "    assert model_name in all_model_list\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train_imputed = imputer.fit_transform(X_train)\n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    if model_name == \"LogisticRegression\":\n",
        "        model = LogisticRegression(max_iter=10000, random_state=random_state)\n",
        "    elif model_name == \"SVM\":\n",
        "        model = SVC(random_state=random_state,probability=True)\n",
        "    elif model_name == \"MLP\":\n",
        "        model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=1000, random_state=random_state)\n",
        "    elif model_name == \"RandomForest\":\n",
        "        model = RandomForestClassifier(n_jobs=3, n_estimators=1000, criterion=\"gini\", random_state=random_state)\n",
        "        model_fullname = \"Random Forest\"\n",
        "    elif model_name == \"XGBoost\":\n",
        "        model = xgb.XGBClassifier(random_state=random_state)\n",
        "        model_fullname = \"XGBoost\"\n",
        "    else:\n",
        "        raise Exception\n",
        "\n",
        "    displayModelHeader(featurePath,targetPath,model_fullname)\n",
        "    if model_name == \"XGBoost\":\n",
        "\n",
        "        model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict = train_model(model, X_train, y_train, X_test, y_test, over_sample) # No need to impute nan values for XGBoost\n",
        "\n",
        "    else:\n",
        "\n",
        "        model, y_pred, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num, cfc_report_dict = train_model(model, X_train_imputed, y_train, X_test_imputed, y_test, over_sample)\n",
        "\n",
        "\n",
        "    save_dir = f\"../output/{dataset_name}/saved\"\n",
        "    check_directory(save_dir)\n",
        "\n",
        "    if model_saving:\n",
        "        if model_name == \"XGBoost\":\n",
        "            save_model(model, None, target_column, dataset_name, model_name, save_dir) # No need to impute nan values for XGBoost\n",
        "        else:\n",
        "            save_model(model, imputer, target_column, dataset_name, model_name, save_dir)\n",
        "\n",
        "    if report_gen:\n",
        "        if model_name in valid_report_list:\n",
        "            if model_name == \"RandomForest\":\n",
        "                importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': model.feature_importances_})\n",
        "                report = importance_df.sort_values(by='Importance', ascending=False)\n",
        "            elif model_name == \"XGBoost\":\n",
        "                importance_df = pd.DataFrame(list(model.get_booster().get_score().items()), columns=[\"Feature\",\"Importance\"])\n",
        "                report = importance_df.sort_values(by='Importance', ascending=False)\n",
        "            else:\n",
        "                raise Exception\n",
        "\n",
        "            report[\"Feature_Name\"] = report[\"Feature\"].apply(report_modify)\n",
        "            report = report.reindex(columns=[\"Feature\",\"Feature_Name\",\"Importance\"])\n",
        "            report.to_csv(os.path.join(save_dir, f\"{target_column}-{dataset_name}-report-{model_name}.csv\"), index=False)\n",
        "        else:\n",
        "            report = None\n",
        "            print(\"No Valid Report for Current Model\")\n",
        "\n",
        "    return featurePath,targetPath,model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num\n",
        "\n",
        "\n",
        "\n",
        "# Save the trained model and nan-value imputer\n",
        "def save_model(model, imputer, target_column, dataset_name, model_name, save_dir):\n",
        "    data = {\n",
        "    \"model\": model,\n",
        "    \"imputer\": imputer\n",
        "    }\n",
        "    with open(os.path.join(save_dir, f\"{target_column}-{dataset_name}-trained-{model_name}.pkl\"), 'wb') as file:\n",
        "        pickle.dump(data, file)\n",
        "\n",
        "# Modify the feature-importance report by adding an industry-correspondence introduction column\n",
        "def report_modify(value):\n",
        "    splitted = value.split(\"-\")\n",
        "    if splitted[0] in [\"Emp\",\"Est\",\"Pay\"]:\n",
        "        try:\n",
        "            modified = splitted[0]+\"-\"+INDUSTRIES_DICT[splitted[1]]+\"-\"+splitted[2]\n",
        "        except:\n",
        "            modified = value\n",
        "        return modified\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "\n",
        "def report_generator(cfc_report_dict, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num):\n",
        "    #transfrom report from dictionary to df\n",
        "    df_report = pd.DataFrame.from_dict(cfc_report_dict).transpose()\n",
        "\n",
        "    #adjust data display format for md and yaml\n",
        "    df_report['support'] = df_report['support'].astype(int)\n",
        "    df_report.iloc[:, 0:3] = df_report.iloc[:, 0:3].round(2)\n",
        "    df_report.iloc[2,0] = \" \"\n",
        "    df_report.iloc[2,1] = \" \"\n",
        "    df_report.iloc[2,3] = df_report.iloc[3,3]\n",
        "\n",
        "    #edit roc_auc format\n",
        "    roc_auc = roc_auc *100\n",
        "\n",
        "    #covert numpy float to python float for yaml display\n",
        "    roc_auc = roc_auc.item()\n",
        "    best_threshold_num = best_threshold_num.item()\n",
        "    gmeans_num = gmeans_num.item()\n",
        "\n",
        "    #markdown file content\n",
        "    markdown_content = f\"\"\"\n",
        "## {model_fullname} Accuracy\n",
        "\n",
        "**ROC-AUC Score:** {roc_auc}% &nbsp;&nbsp; **Best Threshold:** {best_threshold_num} &nbsp;&nbsp; **G-Mean:** {gmeans_num} &nbsp;&nbsp; **Model Accuracy:** {accuracy_num}%\n",
        "\n",
        "                    Precision   Recall      F1-Score    Support\n",
        "\n",
        "    0               {df_report.iloc[0,0]}        {df_report.iloc[0,1]}        {df_report.iloc[0,2]}        {df_report.iloc[0,3]}\n",
        "    1               {df_report.iloc[1,0]}        {df_report.iloc[1,1]}        {df_report.iloc[1,2]}        {df_report.iloc[1,3]}\n",
        "\n",
        "    Accuracy                                {df_report.iloc[2,2]}        {df_report.iloc[3,3]}\n",
        "    Macro Avg       {df_report.iloc[3,0]}        {df_report.iloc[3,1]}        {df_report.iloc[3,2]}        {df_report.iloc[3,3]}\n",
        "    Weighted Avg    {df_report.iloc[4,0]}        {df_report.iloc[4,1]}        {df_report.iloc[4,2]}        {df_report.iloc[3,3]}\n",
        "\"\"\"\n",
        "\n",
        "    #yaml output dictionary\n",
        "    report_dict = {\n",
        "    \"model_fullname\": model_fullname,\n",
        "    \"roc_auc\": roc_auc,\n",
        "    \"best_threshold_num\": best_threshold_num,\n",
        "    \"gmeans_num\": gmeans_num,\n",
        "    \"accuracy_num\": accuracy_num,\n",
        "    \"classification_report\": df_report.to_dict(orient=\"index\")\n",
        "    }\n",
        "\n",
        "    with open(f'{model_name}_accuracy.md','w') as markdown_file:\n",
        "        markdown_file.write(markdown_content)\n",
        "\n",
        "    with open(f'{model_name}_accuracy.yaml', \"w\") as f:\n",
        "        yaml.dump(report_dict, f, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bglCZfAox9gP"
      },
      "outputs": [],
      "source": [
        "# Read the integrated full dataset and do the train-test splitting and save the splitted files\n",
        "if save_training:\n",
        "  integrated_df = pd.read_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}.csv\"))\n",
        "\n",
        "X_total, y_total = df.iloc[:, feature_start_idx:], df.iloc[:, target_idx] #X_total, y_total = integrated_df.iloc[:, feature_start_idx:], integrated_df.iloc[:, target_idx]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.2, random_state=random_state)\n",
        "X_train.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-X-train.csv\"), index=False)\n",
        "X_test.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-X-test.csv\"), index=False)\n",
        "y_train.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-y-train.csv\"), index=False)\n",
        "y_test.to_csv(os.path.join(full_save_dir, f\"{target_column}-{dataset_name}-y-test.csv\"), index=False)\n",
        "\n",
        "if save_training:\n",
        "  file_path = os.path.join(full_save_dir, f\"X_train.csv\")\n",
        "  X_train.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"X_test.csv\")\n",
        "  X_test.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"y_train.csv\")\n",
        "  y_train.to_csv(file_path, index=False)\n",
        "\n",
        "  file_path = os.path.join(full_save_dir, f\"y_test.csv\")\n",
        "  y_test.to_csv(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpmeBMiYx9gP"
      },
      "source": [
        "Model training, testing and results saving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqiy1m6-x9gQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4661f23-fe98-4bd0-fd86-0f74fbb9cd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mModel: Random Forest\u001b\n",
            "Feature path:https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\n",
            "Target path: https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\n",
            "startyear: 2017, endyear: 2021, naics:[6], state: ME\n",
            "Model Fitted Successfully.\n",
            "\u001b[1mROC-AUC Score\u001b[0m \t\t: 55.00000000000001 %\n",
            "\u001b[1mBest Threshold\u001b[0m \t\t: 0.619 \n",
            "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.556\n",
            "\u001b[1mModel Accuracy\u001b[0m \t\t: 66.0 %\n",
            "\u001b[1m\n",
            "Classification Report:\u001b[0m\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.24      0.04      0.07       181\n",
            "         1.0       0.68      0.94      0.79       389\n",
            "\n",
            "    accuracy                           0.66       570\n",
            "   macro avg       0.46      0.49      0.43       570\n",
            "weighted avg       0.54      0.66      0.56       570\n",
            "\n",
            "Directory '../output/bees/saved' already exists.\n"
          ]
        }
      ],
      "source": [
        "# Training Random Forest\n",
        "featurePath, targetPath, model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num= train(features_path ,targets_path,\"RandomForest\", target_column, dataset_name, X_train, y_train, X_test, y_test,\n",
        "      report_gen=True, all_model_list=all_model_list, valid_report_list=valid_report_list, over_sample=False, model_saving=True, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate markdown and yaml file\n",
        "# Results will appear in the content folder to the left\n",
        "report_generator(cfc_report_dict, model_fullname, \"RandomForest\", gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
      ],
      "metadata": {
        "id": "sKhOoFlz2rwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmFTVDnjx9gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5830fe73-66f2-4c6b-bdfb-b85bac0dfb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "startyear: 2017, endyear: 2021, naics:[6], state: ME\n",
            "\u001b[1mModel: XGBoost\u001b\n",
            "Feature path:https://raw.githubusercontent.com/ModelEarth/community-timelines/main/training/naics{naics}/US/counties/{year}/US-{state}-training-naics{naics}-counties-{year}.csv\n",
            "Target path: https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets-increase2022.csv\n",
            "Model Fitted Successfully.\n",
            "\u001b[1mROC-AUC Score\u001b[0m \t\t: 51.0 %\n",
            "\u001b[1mBest Threshold\u001b[0m \t\t: 0.738 \n",
            "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.521\n",
            "\u001b[1mModel Accuracy\u001b[0m \t\t: 60.0 %\n",
            "\u001b[1m\n",
            "Classification Report:\u001b[0m\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.21      0.25       181\n",
            "         1.0       0.68      0.78      0.73       389\n",
            "\n",
            "    accuracy                           0.60       570\n",
            "   macro avg       0.49      0.50      0.49       570\n",
            "weighted avg       0.56      0.60      0.58       570\n",
            "\n",
            "Directory '../output/bees/saved' already exists.\n"
          ]
        }
      ],
      "source": [
        "# Generating dummy values to handle the categorical columns: 'Population-2018', 'Population-2019', 'Population-2020'\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "#Train XGBoost model\n",
        "featurePath,targetPath, model, y_pred, report, model_fullname, cfc_report_dict, accuracy_num, gmeans_num, accuracy_num, roc_auc, best_threshold_num  = train(features_path, targets_path, \"XGBoost\", target_column, dataset_name, X_train, y_train, X_test, y_test,\n",
        "      report_gen=True, all_model_list=all_model_list, valid_report_list=valid_report_list, over_sample=False, model_saving=True, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jQDQdxbx9gS"
      },
      "outputs": [],
      "source": [
        "# Generate Report for XGBoost\n",
        "report_generator(cfc_report_dict, \"XGBoost\", \"XGBoost\", gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load realitystream/models/rbf.py\n",
        "import realitystream.models.rbf as rbfX\n",
        "rbfX.runrbf(param)"
      ],
      "metadata": {
        "id": "Sisc8cmSnMJU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6c28c63b-051d-420b-961d-dc3cfd09337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'realitystream'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ba20b566264a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load realitystream/models/rbf.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrealitystream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbf\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrbfX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrbfX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'realitystream'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}